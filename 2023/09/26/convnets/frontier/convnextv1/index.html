

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="林正">
  <meta name="keywords" content="">
  
    <meta name="description" content="ConvNeXt: A ConvNet for the 2020s  笔者前言 Transformer在NLP任务上取得了非常好的效果，在这之后，为图像任务打造的Vision Transformer再一次刷新了ImageNet数据集上的精度。但在这期间一直有一个争论，那就是Transformer到底是好在Attention这种特殊的计算，还是其因为有超大感受野，从而能够捕捉长期依赖。ConvNe">
<meta property="og:type" content="article">
<meta property="og:title" content="ConvNeXt：A ConvNet for the 2020s">
<meta property="og:url" content="https://jesseprince.github.io/2023/09/26/convnets/frontier/convnextv1/index.html">
<meta property="og:site_name" content="林正的Blog">
<meta property="og:description" content="ConvNeXt: A ConvNet for the 2020s  笔者前言 Transformer在NLP任务上取得了非常好的效果，在这之后，为图像任务打造的Vision Transformer再一次刷新了ImageNet数据集上的精度。但在这期间一直有一个争论，那就是Transformer到底是好在Attention这种特殊的计算，还是其因为有超大感受野，从而能够捕捉长期依赖。ConvNe">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-09-26T11:53:39.323Z">
<meta property="article:modified_time" content="2023-09-27T12:44:40.270Z">
<meta property="article:author" content="林正">
<meta property="article:tag" content="智能系统">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="计算机视觉">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ConvNeXt：A ConvNet for the 2020s - 林正的Blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"jesseprince.github.io","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="林正的Blog" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>林正的Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ConvNeXt：A ConvNet for the 2020s"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-09-26 19:53" pubdate>
          2023年9月26日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          5.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          45 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">ConvNeXt：A ConvNet for the 2020s</h1>
            
              <p class="note note-info">
                
                  
                    <!-- compatible with older versions-->
                    本文最后更新于：2023年9月27日 晚上
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="convnext-a-convnet-for-the-2020s"><a class="markdownIt-Anchor" href="#convnext-a-convnet-for-the-2020s"></a> ConvNeXt: A ConvNet for the 2020s</h1>
<h2 id="笔者前言"><a class="markdownIt-Anchor" href="#笔者前言"></a> 笔者前言</h2>
<p>Transformer在NLP任务上取得了非常好的效果，在这之后，为图像任务打造的Vision Transformer再一次刷新了ImageNet数据集上的精度。但在这期间一直有一个争论，那就是Transformer到底是好在Attention这种特殊的计算，还是其因为有超大感受野，从而能够捕捉长期依赖。ConvNets(卷积神经网络)就真的不如Transformer吗？这篇文章就尝试改进网络的设计来对齐Transformer的性能，并且最终结果表明，改进的纯卷积网络性能是可以超过Transformer的。这个工作来自于老朋友Facebook AI Research和UC Berkeley大学。</p>
<p><strong>原Paper发布日期</strong>：2022.5.2于’<a target="_blank" rel="noopener" href="http://arxiv.org">arxiv.org</a>’, 文章号：2201.03545</p>
<h2 id="摘要abstract"><a class="markdownIt-Anchor" href="#摘要abstract"></a> 摘要Abstract</h2>
<div class="note note-success">
            <p>2020年代，视觉识别领域随着Vision Transformer(ViT)的出现而热闹起来，它快速取代了卷积神经网络在图像识别领域“最先进模型”的地位。但另一方面，一个一般的ViT却在更广泛的计算机视觉任务上(比如目标检测和语义分割)面临困难。是分层级的Transformers(比如Swin Transformer)重新引入了一些卷积网络的先前的优点，使得Vision Transformer能够在实际上作为一个通用的Backbone，从而在各种不同的计算机视觉任务上表现出非凡的性能。但是，这种混合方式的有效性很大程度上归功于Transformer的内在优势，而不是卷积神经网络固有的归纳偏置。在这份工作中，我们重新检验卷积网络的改进空间，并测试一个纯卷积神经网络能够达到的极限。我们沿着ViT的设计方法逐渐“现代化”一个标准的ResNet，然后在这个过程中发现了几个能够影响性能的关键因素。我们的发现产出了一系列纯卷积神经网络模型，被我们称作ConvNeXt家族。这些模型是完全由标准的卷积神经网络模块构成的，ConvNeXt能够在准确率和Scalability上很好的与Transformers抗衡，在ImageNet数据集上达到了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>87.8</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">87.8\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">8</span><span class="mord">7</span><span class="mord">.</span><span class="mord">8</span><span class="mord">%</span></span></span></span>的top-1准确度，并超越了Swin Transformers在COCO检测任务和ADE20K分割任务上的性能，同时还保持了标准卷积神经网络的简单，高效的性质。</p>
          </div>
<p>这篇文章的摘要写的非常精彩，建议阅读原文。作者主要就在阐述Vision Transformer在视觉领域带来的性能提升，一下子打败了所有的卷积神经网络，但好奇卷积神经网络能不能通过改进，比如对齐Transformer的设计来获得同样好的性能。原文中提到了融合进Transformer的设计只是卷积网络层级化的部分，所以发挥主要作用的还是Transformer，他们并没有将卷积网络的归纳偏置带进去，所以在卷积网络存在归纳偏置的情况下能不能有相同的性能还不知道。通过改进，他们发现卷积网络还真能超过Transformer，他们把设计出的模型叫做ConvNeXt，意味着是下一代卷积神经网络。</p>
<h2 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction"></a> 1 Introduction</h2>
<div class="note note-success">
            <p>当我们回溯到2010年代，会发现这十年是以深度学习的巨大进步和深远影响为标志的，主要驱动力就是那些被新提出的神经网络，特别是一系列的卷积神经网络。在这十年中，视觉识别领域成功从特征工程转变成了设计卷积神经网络的结构。尽管使用反向传播算法训练卷积神经网络可以一路追溯到1980年代，我们直到2012年才看到了卷积网络在视觉特征学习上真正的潜力。AlexNet的出现带来了属于ImageNet的时刻，迎来了计算机视觉的新纪元。这个领域从此开始了快速的演进。代表性的卷积网络例如VGGNet，Inceptions，ResNe(X)t，DenseNet，MobileNet，EfficientNet和RegNet的设计聚焦在在准确度，高效率和Scalability这三个不同的方面，并使得一些很有用的设计准则流行起来。</p>
          </div>
<p>这一段实际上就简单回顾了一下渡过AI寒冬的深度学习，随着AlexNet在2012年一鸣惊人，深度学习就开始了快速发展，然后将重要的一些模型名字列举了一下，这些网络改进的方向有准确度，高效率(更少的参数带来更好的性能)，和Scalability。同样的，故事写的很精彩。</p>
<div class="note note-success">
            <p>在计算机视觉领域，卷积网络的完全主导地位并不是一个巧合，在很多应用场景下，&quot;滑动窗口&quot;在视觉处理上都是一个固有的策略，尤其是在处理高分辨率图像的时候。卷积网络拥有一些内在的归纳偏置特性，使得它能够很好适应广泛的计算机视觉应用。最重要的就是平移等价(平移不变)性质，这是在例如目标检测任务中我们想要的性质，卷积网络本身还很高效，因为当我们使用滑动窗口的时候，计算的负载是共享的。在几十年来，这一直都是卷积网络的默认使用方法，一般都在有限物体类别的任务上，例如手写数字识别，面部检测和行人检测。进入2010年代，基于区域的检测器的提出，将卷积网络的地位提升到了作为视觉识别系统的基本构成模块。</p>
          </div>
<p>这一段提了一下卷积操作的本质和其本身就有的特性，重新说了一下Yann LeCun强调的平移不变性质，卷积网络比起Transformer在计算上就是更高效的。我们以前用卷积网络来直接做任务，例如LeNet用在手写数字识别上。后来区域检测器（例如R-CNN）将卷积网络用成了一个基本构建模块，比如我们常说的Backbone，它把卷积网络作为特征提取器来用，然后让它和其它模块配合来完成更复杂的任务。当然这个使用方法一般是Pretraining + fine-tuning的方式。</p>
<div class="note note-success">
            <p>与此同时呢，用于自然语言处理的神经网络有着非常不同的探索过程，因为Transformer取代了循环神经网络成为了支配地位的backbone。尽管语言和视觉领域任务兴趣点差异很大，随着Vision Transformer的出现完全改变了网络结构设计的格局，这两个不同的流派在2020年意外的合并在了一起。除了最初的“Patchify”层，其将一张输入的图片分割成了一系列的图像块，ViT没有引入图像上的归纳偏置，并且相对于原NLP使用的Transformer制作了很少的改变。我们聚焦的ViT的一个主要特点就是它的Scaling行为：如果有更大的模型和更大的数据集，Transformers能够表现的比一个标准的ResNet要显著的好。那些在图像分类上的结果是鼓舞人心的，但计算机视觉又不仅限于图像分类。就像之前讨论过的一样，在过去几十年，对于众多计算机视觉任务的解决方案很大程度上依赖于一个滑动窗口，也就是全卷积的设计范式。没有了卷积网络的归纳偏置，一个一般的ViT模型在成为一个通用的视觉Backbone上面临了诸多挑战。最大的挑战就是ViT的全局注意力机制设计，这使得它的计算复杂度是和输入图像的大小程二次方关系的。这对于ImageNet上的图像分类任务还算是可接受的，但很快发现在更高分辨率输入的任务上变得棘手。</p>
          </div>
<p>这段主要在讲用在视觉上得Transformer的设计和问题。Vision Transformer的第一层，也就是Patch Embedding层使用了不重叠卷积来实现图像的分块，这可以算是用到了卷积的归纳偏置，但后面所有的操作都是和NLP上的Transformer对齐的。Transformer这么引人注目就是他的Scalability，也就是说模型更大，数据集更大，我的模型表现得性能就会更好，我获得更好模型的方式只需要不断扩大参数量和数据量就行了。但ViT在下游计算机视觉任务上(除开分类，包括检测，分割等等)又表现得不好，其中一个最大得问题就是输入高分辨率图片得时候，Transformer的计算量会变得非常大。而下游的这些任务一般都是要输入高分辨率图片的。</p>
<div class="note note-success">
            <p>层级化的Transformer用了一个混合的方式来弥补这一差距。比如说，“滑动窗口”策略(比如Swin-T里的局部窗口注意力)被重新引入到Transformer，让他们表现得更加像卷积网络。Swin Transformer就是这个方向的里程碑工作，第一次展现了Transformer能够被用作一个通用的视觉Backbone，并在一系列远超过图像分类的计算机视觉任务上取得最顶尖的效果。Swin Transformer的成功和快速的应用也揭露了一件事：卷积的要素并没有变得无关紧要，恰恰相反，它仍然是我们想要的，并且从未褪色。</p>
          </div>
<p>这里再次提到了Swin-T将卷积里边一些性质融合进来设计，并且确实能解决一些问题，Swin-T就解决了Transformer作为通用backbone的问题。最后一句话写的很精彩，卷积并没有变得无关紧要，它从未褪色。</p>
<div class="note note-success">
            <p>从这个视角下看呢，许多Transformer在计算机视觉上的进步都是在把卷积操作给带回来。这些带回卷积的尝试，却有一个代价：简单实现滑动窗口的自注意力机制可能在计算上是昂贵的，如果用一些先进的方法，比如循环移位，计算的速度能够被优化，但是系统的设计变得更加复杂。在另一方面，一个几乎讽刺的事实是卷积网络早已满足了许多这些我们想要的特性，尽管以一种直接了当，朴实无华的方式满足的。卷积网络看起来在失去动力的唯一原因是(层级的)Transformers在许多视觉任务上超越了它们，性能上的不同通常归功于Transformer的更优越的scaling行为，其中多头自注意力机制是一个关键因素。</p>
          </div>
<p>这一段开始直截了当的批评Transformer，我们让ViT进步的方式就是把卷积的特性带回来，那卷积网络不已经有这些特性了吗，我们干嘛还费劲这么做呢？而且越是融合卷积的特性这个网络的设计就越是复杂，不太符合最简单的设计是最有效的这种哲理。最后点明，卷积看起来要输了的原因是因为Transformer的Scalability很强，这才使得它们在很多任务上超越了卷积。</p>
<div class="note note-success">
            <p>不像卷积神经网络已经在过去十年被逐步改进，Vsion Transformer的采用则是一步促成的。在最近的文献中，在比较两者时通常在使用系统级比较(比如Swin-T对比ResNet)。卷积网络和Vision Transformer同时变得不同，又变得相同：它们都配备了相似的归纳偏置，但在训练过程，以及宏观/微观上的结构设计上存在显著差异。在本工作中，我们调查卷积网络和Transformer之间的结构区别，并尝试弄清楚在比较网络性能时混淆的变量因素。我们的研究旨在弥合卷积网络在ViT前时代和ViT后时代的差距，并测试一个纯卷积网络可以实现的极限。</p>
          </div>
<p>第一句话就在说ViT就是突然从NLP那里拿过来套上的，不像卷积一直被改进了十年。在比较基于Transformer的模型和基于卷积的模型的时候，是在系统层面上比较的，可能存在一些应该控制的变量(比如通道数量，优化器等等)，然后引出本文的工作，就是在ViT推出之前的时代和ViT推出之后的时代弥合卷积网络的性能差距，并且尝试把卷积网络的性能推到极限。</p>
<div class="note note-success">
            <p>为了做到这点，我们从一个标准的ResNet开始(比如ResNet50)，并让它在一个升级的训练流程上训练。我们逐渐&quot;现代化&quot;它的结构，使其对齐层级化ViT的结构(比如Swin-T)。我们的探索工作被一个关键问题领导：Transformer中的设计决策会怎样影响卷积网络的性能？我们在这个过程中发现了一些导致性能差异的关键因素。最终结果，我们提出了被称作ConvNeXt的纯卷积网络家族。我们在一系列视觉任务上，例如ImageNet图像分类，COCO数据集目标检测/分割和ADE20K的语义翻个上评估ConvNeXt系列的性能。令人惊喜的是，ConvNeXt，这个由标准卷积模块构成的模型，能够在所有主要的评分指标中，在精准度，Scalability和鲁棒性上很好的与Transformer抗衡。ConvNeXt维持了标准的卷积网络的高效性，并且在训练和测试上全卷积的性质使其在实现上非常简单</p>
          </div>
<p>这一段简单介绍了读者接下来要看到的内容，他们从ResNet开始改进，然后将Transformer的设计逐步融合进来，相当于整个改进过程都是一个消融实验，最后发现了影响性能的关键因素。他们改进后的卷积网络叫做ConvNeXt，这个网络在很多指标上都有Transformer的性能，甚至超越了Transformer的性能。由于模型只用了卷积，所以实现起来是很简单的，并且计算相当高效。</p>
<div class="note note-success">
            <p>我们希望新的发现和讨论能够挑战一些大家都相信的东西，并且能够鼓励人们重新思考卷积在计算机视觉中的重要性。</p>
          </div>
<p>最后一句话直接升华这篇工作的地位，其实总的来说他们就是在把Transformer的设计缝进来调参，但经过整个一个讲述，似乎在打破领域的迷信(比如一些人就认为Transformer厉害，注意力机制天下无敌)，让人们重新重视卷积，就像是在掀起CV领域的革命一般。但不能否认的是Facebook烧了不少电费告诉我们哪些技巧对改进性能有用。</p>
<h2 id="2-modernizing-a-convnet-a-roadmap现代化一个卷积网络一张路线图"><a class="markdownIt-Anchor" href="#2-modernizing-a-convnet-a-roadmap现代化一个卷积网络一张路线图"></a> 2 Modernizing a ConvNet: a Roadmap：现代化一个卷积网络：一张路线图</h2>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" class="category-chain-item">现代计算机视觉</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%8E%B0%E4%BB%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%89%8D%E6%B2%BF%E7%A0%94%E7%A9%B6/" class="category-chain-item">前沿研究</a>
  
  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%99%BA%E8%83%BD%E7%B3%BB%E7%BB%9F/">#智能系统</a>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>
      
        <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">#计算机视觉</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ConvNeXt：A ConvNet for the 2020s</div>
      <div>https://jesseprince.github.io/2023/09/26/convnets/frontier/convnextv1/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>林正</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年9月26日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/09/26/convnets/frontier/frontierinfo/" title="0介绍">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">0介绍</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/09/26/master/matrixanalysis/matrixanalysisinfo/" title="00：课程信息">
                        <span class="hidden-mobile">00：课程信息</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script>(function (w, d, s, id) {
            if (typeof (w.webpushr) !== 'undefined') return; w.webpushr = w.webpushr || function () { (w.webpushr.q = w.webpushr.q || []).push(arguments) }; var js, fjs = d.getElementsByTagName(s)[0]; js = d.createElement(s); js.id = id; js.async = 1; js.src = "https://cdn.webpushr.com/app.min.js";fjs.parentNode.appendChild(js);}(window, document, 'script', 'webpushr-jssdk'));webpushr('setup', { 'key': 'BMbTx1ZJelWq3roP3GYnfCDQdvu4yiHno_QBdQaV8otW_Gag0xTRGJUHBpbfDkyq3LD9yOS_CwXnaIkg7E1ijgo' });</script></body>
</html>
